{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sk2470423/sk2470423/blob/main/files___exceptional_handling_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1 Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where\n",
        "multiprocessing is a better choice\n",
        "\n",
        "ANS--> Multithreading\n",
        "\n",
        "Multithreading executes multiple threads within a single process, sharing memory space.\n",
        "\n",
        "Preferable Scenarios\n",
        "\n",
        "1. I/O-bound operations: Multithreading excels at handling concurrent I/O-bound tasks, such as network requests, database queries or file operations, where waiting for I/O operations is a significant portion of the task.\n",
        "2. GUI applications: Multithreading helps maintain responsive graphical user interfaces by performing time-consuming tasks in background threads.\n",
        "3. Real-time systems: Multithreading is suitable for real-time systems requiring quick responses to events.\n",
        "4. Memory-intensive applications: Sharing memory reduces memory usage.\n",
        "\n",
        "Limitations\n",
        "\n",
        "1. Global Interpreter Lock (GIL): In languages like Python, GIL prevents true parallel execution of threads, limiting performance.\n",
        "2. Synchronization complexity: Managing shared resources increases complexity.\n",
        "3. Debugging challenges: Multithreaded programs can be difficult to debug.\n",
        "\n",
        "Multiprocessing\n",
        "\n",
        "Multiprocessing executes multiple processes, each with its own memory space.\n",
        "\n",
        "Preferable Scenarios\n",
        "\n",
        "1. CPU-bound operations: Multiprocessing is ideal for CPU-intensive tasks like scientific computing, data compression or encryption.\n",
        "2. Parallel computation: Independent tasks benefit from true parallel execution.\n",
        "3. Large-scale computations: Breaking tasks into smaller processes aids distributed computing.\n",
        "4. Avoiding GIL limitations: Languages with GIL, like Python, benefit from multiprocessing for CPU-bound tasks.\n",
        "\n",
        "Limitations\n",
        "\n",
        "1. Inter-process communication (IPC) overhead: Sharing data between processes is costly.\n",
        "2. Higher memory usage: Each process requires separate memory.\n",
        "3. Process creation overhead: Starting processes is slower than threads.\n",
        "\n",
        "Key Considerations\n",
        "\n",
        "1. Task independence: If tasks are highly independent, multiprocessing might be better. For tasks sharing resources, multithreading could be preferred.\n",
        "2. Resource constraints: Multithreading conserves memory; multiprocessing may require more.\n",
        "3. Language and framework support: Choose based on language capabilities and libraries available.\n",
        "4. Debugging and complexity: Multithreading can be more complex; multiprocessing might simplify debugging.\n"
      ],
      "metadata": {
        "id": "YOnI0PVcNZjt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. Describe what a process pool is and how it helps in managing multiple processes efficiently\n",
        "\n",
        "Process Pool Overview\n",
        "\n",
        "A process pool is a design pattern that manages multiple processes efficiently by reusing existing processes, reducing creation overhead and improving resource utilization. It's a container for a group of worker processes, allowing tasks to be executed concurrently.\n",
        "\n",
        "Key Benefits\n",
        "\n",
        "1. Efficient resource utilization: Reduces memory usage and minimizes process creation overhead.\n",
        "2. Improved responsiveness: Faster task execution due to reused processes.\n",
        "3. Better fault tolerance: Isolated worker processes prevent single-task failures from affecting the entire pool.\n",
        "4. Simplified task management: Centralized control for task distribution, monitoring and error handling.\n",
        "\n",
        "Process Pool Components\n",
        "\n",
        "1. Worker processes: Execute tasks from the pool's task queue.\n",
        "2. Task queue: Holds tasks waiting for execution.\n",
        "3. Pool manager: Supervises worker processes, task distribution and pool configuration.\n",
        "\n",
        "Process Pool Workflow\n",
        "\n",
        "1. Task submission: Tasks are added to the task queue.\n",
        "2. Worker selection: Available worker processes are selected.\n",
        "3. Task execution: Selected worker processes execute tasks.\n",
        "4. Result retrieval: Task results are collected and returned.\n",
        "5. Worker reuse: Worker processes return to the pool for reuse.\n",
        "\n",
        "Implementation Examples\n",
        "\n",
        "1. Python's multiprocessing.Pool: Provides a process pool implementation.\n",
        "2. Concurrent.futures.ProcessPoolExecutor: Offers a high-level interface for process pools.\n",
        "\n",
        "Best Practices\n",
        "\n",
        "1. Optimize pool size: Balance pool size with available resources.\n",
        "2. Monitor task queue: Prevent overflow and adjust pool size accordingly.\n",
        "3. Implement error handling: Handle worker process failures gracefully.\n",
        "4. Use inter-process communication: Efficiently exchange data between worker processes."
      ],
      "metadata": {
        "id": "B8l3mPvKPyXf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. Explain what multiprocessing is and why it is used in Python programs\n",
        "\n",
        "Multiprocessing in Python\n",
        "\n",
        "Multiprocessing is a programming technique where multiple processes are executed concurrently, improving responsiveness, efficiency and system utilization.\n",
        "\n",
        "What is Multiprocessing?\n",
        "\n",
        "Multiprocessing involves creating multiple operating system-level processes to execute tasks independently. Each process has its own memory space, and communication between processes requires inter-process communication (IPC) mechanisms.\n",
        "\n",
        "Why Use Multiprocessing in Python?\n",
        "\n",
        "1. CPU-bound tasks: Multiprocessing bypasses Python's Global Interpreter Lock (GIL), allowing true parallel execution of CPU-intensive tasks.\n",
        "2. Concurrency: Improves responsiveness by executing tasks concurrently.\n",
        "3. Scalability: Utilizes multiple CPU cores for computation-intensive tasks.\n",
        "4. Fault tolerance: Isolated processes prevent single-task failures from affecting the entire program.\n",
        "\n",
        "Multiprocessing in Python: Key Modules\n",
        "\n",
        "1. multiprocessing: Provides basic multiprocessing functionality.\n",
        "2. concurrent.futures (ProcessPoolExecutor): Offers high-level interface for multiprocessing.\n",
        "\n",
        "Example Usage\n"
      ],
      "metadata": {
        "id": "AyyDNBupQOE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "def worker(num):\n",
        "    print(f\"Worker {num} started\")\n",
        "    time.sleep(2)\n",
        "    print(f\"Worker {num} finished\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    processes = []\n",
        "    for i in range(5):\n",
        "        p = multiprocessing.Process(target=worker, args=(i,))\n",
        "        processes.append(p)\n",
        "        p.start()\n",
        "\n",
        "    for p in processes:\n",
        "        p.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SI7RwGLmRTMK",
        "outputId": "31ec7a7a-c57c-44c4-f448-2a2a3ef13bb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Worker 0 started\n",
            "Worker 1 started\n",
            "Worker 2 started\n",
            "Worker 3 started\n",
            "Worker 4 started\n",
            "Worker 0 finishedWorker 1 finished\n",
            "\n",
            "Worker 2 finished\n",
            "Worker 3 finishedWorker 4 finished\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Practices\n",
        "\n",
        "1. Protect entry point: Use if __name__ == \"__main__\" to prevent child processes from executing the same code.\n",
        "2. Manage inter-process communication: Use queues, pipes or shared memory for IPC.\n",
        "3. Optimize process count: Balance process count with available CPU cores.\n",
        "4. Handle process failures: Implement error handling mechanisms.\n",
        "\n",
        "Advantages\n",
        "\n",
        "1. Improved performance\n",
        "2. Enhanced responsiveness\n",
        "3. Better resource utilization\n"
      ],
      "metadata": {
        "id": "yY38-XW6Rp6y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Write a Python program using multithreading where one thread adds numbers to a list, and another\n",
        "thread removes numbers from the list. Implement a mechanism to avoid race conditions using\n",
        "threading.Lock."
      ],
      "metadata": {
        "id": "8pmtfoWGRt9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Shared list\n",
        "numbers = []\n",
        "\n",
        "# Lock for thread synchronization\n",
        "lock = threading.Lock()\n",
        "\n",
        "# Thread 1: Adds numbers to the list\n",
        "def add_numbers():\n",
        "    for _ in range(10):\n",
        "        with lock:  # Acquire lock\n",
        "            num = random.randint(1, 100)\n",
        "            numbers.append(num)\n",
        "            print(f\"Added: {num}\")\n",
        "        time.sleep(0.5)  # Simulate work\n",
        "\n",
        "# Thread 2: Removes numbers from the list\n",
        "def remove_numbers():\n",
        "    for _ in range(10):\n",
        "        with lock:  # Acquire lock\n",
        "            if numbers:\n",
        "                num = numbers.pop(0)\n",
        "                print(f\"Removed: {num}\")\n",
        "            else:\n",
        "                print(\"List empty\")\n",
        "        time.sleep(0.7)  # Simulate work\n",
        "\n",
        "# Create threads\n",
        "add_thread = threading.Thread(target=add_numbers)\n",
        "remove_thread = threading.Thread(target=remove_numbers)\n",
        "\n",
        "# Start threads\n",
        "add_thread.start()\n",
        "remove_thread.start()\n",
        "\n",
        "# Wait for threads to finish\n",
        "add_thread.join()\n",
        "remove_thread.join()\n",
        "\n",
        "print(\"Final List:\", numbers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofvhElbWRXVH",
        "outputId": "9a33b72e-f448-436d-8706-de8c9d4ed9cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added: 81\n",
            "Removed: 81\n",
            "Added: 72\n",
            "Removed: 72\n",
            "Added: 33\n",
            "Removed: 33\n",
            "Added: 76\n",
            "Added: 31\n",
            "Removed: 76\n",
            "Added: 89\n",
            "Removed: 31\n",
            "Added: 70\n",
            "Added: 17\n",
            "Removed: 89\n",
            "Added: 19\n",
            "Removed: 70\n",
            "Added: 88\n",
            "Removed: 17\n",
            "Removed: 19\n",
            "Removed: 88\n",
            "Final List: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. Describe the methods and tools available in Python for safely sharing data between threads and\n",
        "processes.\n",
        "\n",
        "ANS--> Thread-Safe Data Sharing\n",
        "\n",
        "1. threading.Lock:  Exclusive access to shared resources.\n",
        "2. threading.RLock:  Reentrant lock for nested access.\n",
        "3. threading.Semaphore:  Limit concurrent access.\n",
        "4. queue.Queue:  Thread-safe queue for producer-consumer patterns.\n",
        "5. threading.Event:  Coordinate threads with events.\n",
        "\n",
        "Process-Safe Data Sharing\n",
        "\n",
        "1. multiprocessing.Pipe:  Inter-process communication (IPC) pipe.\n",
        "2. multiprocessing.Queue:  Process-safe queue.\n",
        "3. multiprocessing.Manager:  Shared data structures (e.g., lists, dictionaries).\n",
        "4. multiprocessing.SharedMemory:  Shared memory blocks.\n",
        "5. concurrent.futures.ProcessPoolExecutor:  High-level process management.\n",
        "\n",
        "Data Structures\n",
        "\n",
        "1. threading.local:  Thread-local storage.\n",
        "2. multiprocessing.Manager().dict():  Shared dictionary.\n",
        "3. multiprocessing.Manager().list():  Shared list.\n",
        "\n",
        "Best Practices\n",
        "\n",
        "1. Minimize shared data.\n",
        "2. Use locks and semaphores judiciously.\n",
        "3. Avoid shared state when possible.\n",
        "4. Use high-level concurrency libraries.\n",
        "5. Document shared data access.\n",
        "\n",
        "Recommended Libraries\n",
        "\n",
        "1. concurrent.futures\n",
        "2. multiprocessing\n",
        "3. threading\n",
        "4. queue\n",
        "5. numpy (for shared memory arrays)\n",
        "\n",
        "Additional Resources\n",
        "\n",
        "1. Python documentation: \"Concurrency\"\n",
        "2. \"Python Concurrency Essentials\" by Matt A. Wood\n",
        "3. \"Concurrency in Python\" tutorial by Real Python"
      ],
      "metadata": {
        "id": "PsJ9Bm6YSH4e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for\n",
        "doing so.\n",
        "\n",
        "Importance of Exception Handling\n",
        "\n",
        "1. Preventing Program Termination: Unhandled exceptions can terminate the entire program, including all threads or processes.\n",
        "2. Maintaining Data Integrity: Exceptions can lead to inconsistent data states, especially in shared resources.\n",
        "3. Ensuring Responsiveness: Unhandled exceptions can cause deadlock or livelock situations.\n",
        "4. Improving Debuggability: Proper exception handling aids in identifying and resolving concurrency issues.\n",
        "\n",
        "Techniques for Exception Handling\n",
        "\n",
        "Thread-Level Exception Handling\n",
        "\n",
        "1. try-except blocks: Wrap thread code to catch and handle exceptions.\n",
        "2. threading.excepthook: Custom exception handling for threads.\n",
        "3. Thread-specific exception handling: Use threading.Thread subclassing.\n",
        "\n",
        "Process-Level Exception Handling\n",
        "\n",
        "1. try-except blocks: Wrap process code to catch and handle exceptions.\n",
        "2. multiprocessing.Process subclassing: Customize exception handling.\n",
        "3. Queue-based exception handling: Use multiprocessing.Queue for error reporting.\n",
        "\n",
        "High-Level Concurrency Libraries\n",
        "\n",
        "1. concurrent.futures: Built-in exception handling mechanisms.\n",
        "2. asyncio: Support for asynchronous exception handling.\n",
        "\n",
        "Best Practices\n",
        "\n",
        "1. Centralize exception handling: Use a single handler for all threads or processes.\n",
        "2. Log exceptions: Record exceptions for post-mortem analysis.\n",
        "3. Test thoroughly: Ensure exception handling works correctly.\n",
        "4. Document exception handling: Clarify exception handling strategies.\n",
        "\n",
        "Common Pitfalls\n",
        "\n",
        "1. Swallowing exceptions: Avoid hiding exceptions without proper handling.\n",
        "2. Uncaught exceptions: Ensure all exceptions are caught and handled.\n",
        "3. Deadlock risk: Avoid locking mechanisms that can lead to deadlocks.\n",
        "\n",
        "Additional Resources\n",
        "\n",
        "1. Python documentation: \"Concurrency\" and \"Exceptions\"\n",
        "2. \"Python Concurrency Essentials\" by Matt A. Wood\n",
        "3. \"Concurrency in Python\" tutorial by Real Python\n",
        "\n",
        "Example code for exception handling in concurrent programs:"
      ],
      "metadata": {
        "id": "chiUeJxTS7Qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import concurrent.futures\n",
        "\n",
        "def thread_func():\n",
        "    try:\n",
        "        # Code that may raise exceptions\n",
        "        1 / 0\n",
        "    except ZeroDivisionError:\n",
        "        print(\"Handled ZeroDivisionError\")\n",
        "\n",
        "# Thread-level exception handling\n",
        "thread = threading.Thread(target=thread_func)\n",
        "thread.start()\n",
        "thread.join()\n",
        "\n",
        "# Process-level exception handling with concurrent.futures\n",
        "def process_func():\n",
        "    try:\n",
        "        1 / 0\n",
        "    except ZeroDivisionError:\n",
        "        print(\"Handled ZeroDivisionError\")\n",
        "\n",
        "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
        "    future = executor.submit(process_func)\n",
        "    future.result()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olbfxZSjTRXP",
        "outputId": "939609b0-8ccf-4e8f-9f34-5aba7db5cbd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Handled ZeroDivisionError\n",
            "Handled ZeroDivisionError\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently.\n",
        "Use concurrent.futures.ThreadPoolExecutor to manage the threads.\n",
        "\n"
      ],
      "metadata": {
        "id": "0puV9Tc5TcgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "import math\n",
        "\n",
        "def calculate_factorial(n):\n",
        "    \"\"\"Calculate factorial of n\"\"\"\n",
        "    result = math.factorial(n)\n",
        "    print(f\"Factorial of {n}: {result}\")\n",
        "    return result\n",
        "\n",
        "def main():\n",
        "    # Create thread pool with 5 worker threads\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
        "        # Submit tasks to thread pool\n",
        "        futures = {executor.submit(calculate_factorial, i): i for i in range(1, 11)}\n",
        "\n",
        "        # Monitor task completion\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            idx = futures[future]\n",
        "            try:\n",
        "                future.result()  # Ensure task completed successfully\n",
        "            except Exception as e:\n",
        "                print(f\"Error calculating factorial of {idx}: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuJUanO6T4Yz",
        "outputId": "94e49191-613d-4f8d-ff51-627653808fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Factorial of 1: 1\n",
            "Factorial of 2: 2\n",
            "Factorial of 3: 6\n",
            "Factorial of 4: 24\n",
            "Factorial of 5: 120\n",
            "Factorial of 6: 720Factorial of 7: 5040\n",
            "Factorial of 8: 40320\n",
            "Factorial of 9: 362880\n",
            "\n",
            "Factorial of 10: 3628800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in\n",
        "parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8\n",
        "processes)\n",
        "\n"
      ],
      "metadata": {
        "id": "aVmaep7DUKgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "def square(x):\n",
        "    \"\"\"Calculate square of x\"\"\"\n",
        "    return x * x\n",
        "\n",
        "def parallel_computation(pool_size):\n",
        "    numbers = range(1, 11)\n",
        "    start_time = time.time()\n",
        "\n",
        "    with multiprocessing.Pool(pool_size) as pool:\n",
        "        results = pool.map(square, numbers)\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "\n",
        "    print(f\"Pool size: {pool_size}, Time taken: {elapsed_time:.4f} seconds\")\n",
        "    return results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pool_sizes = [1, 2, 4, 8]\n",
        "    for size in pool_sizes:\n",
        "        parallel_computation(size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUov3xtYUJL1",
        "outputId": "dc7526b4-b03c-4f60-b0c0-a26394341fd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pool size: 1, Time taken: 0.0187 seconds\n",
            "Pool size: 2, Time taken: 0.0223 seconds\n",
            "Pool size: 4, Time taken: 0.0443 seconds\n",
            "Pool size: 8, Time taken: 0.0722 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5jOzywxYU577"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}